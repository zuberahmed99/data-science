{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000027E8013E710>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000027E8013E7B8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000027E8013E5C0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = 10\n",
    "inputSize = 784\n",
    "hiddenUnits = 150\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputSize])\n",
    "y = tf.placeholder(tf.float32, shape = [None, classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing the weights and biases\n",
    "W1 = tf.Variable(tf.truncated_normal([inputSize, hiddenUnits], stddev=0.1))\n",
    "B1 = tf.Variable(tf.constant(0.1),[hiddenUnits])\n",
    "W2 = tf.Variable(tf.truncated_normal([hiddenUnits, classes], stddev=0.1))\n",
    "B2 = tf.Variable(tf.constant(0.1),[classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hiddenLayerOutput = tf.matmul(X, W1) + B1\n",
    "hiddenLayerOutput = tf.nn.relu(hiddenLayerOutput)\n",
    "finalOutput = tf.matmul(hiddenLayerOutput, W2) + B2\n",
    "finalOutput = tf.nn.relu(finalOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = finalOutput))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(finalOutput,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.11\n",
      "step 1000, training accuracy 0.94\n",
      "step 2000, training accuracy 0.95\n",
      "step 3000, training accuracy 0.98\n",
      "step 4000, training accuracy 1\n",
      "step 5000, training accuracy 0.98\n",
      "step 6000, training accuracy 1\n",
      "step 7000, training accuracy 0.98\n",
      "step 8000, training accuracy 0.99\n",
      "step 9000, training accuracy 0.99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    batchInput = batch[0]\n",
    "    batchLabels = batch[1]\n",
    "    _, trainingLoss = sess.run([opt, loss], feed_dict={X: batchInput, y: batchLabels})\n",
    "    if i%1000 == 0:\n",
    "        trainAccuracy = accuracy.eval(session=sess, feed_dict={X: batchInput, y: batchLabels})\n",
    "        print (\"step %d, training accuracy %g\"%(i, trainAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.9746000170707703\n"
     ]
    }
   ],
   "source": [
    "testInputs = mnist.test.images\n",
    "testLabels = mnist.test.labels\n",
    "acc = accuracy.eval(session=sess, feed_dict = {X: testInputs, y: testLabels})\n",
    "print(\"testing accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numHiddenUnitsLayer2 = 100\n",
    "trainingIterations = 10000\n",
    "tf.reset_default_graph() \n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputSize])\n",
    "y = tf.placeholder(tf.float32, shape = [None, classes])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([inputSize, hiddenUnits], stddev=0.1))\n",
    "B1 = tf.Variable(tf.constant(0.1), [hiddenUnits])\n",
    "W2 = tf.Variable(tf.random_normal([hiddenUnits, numHiddenUnitsLayer2], stddev=0.1))\n",
    "B2 = tf.Variable(tf.constant(0.1), [numHiddenUnitsLayer2])\n",
    "W3 = tf.Variable(tf.random_normal([numHiddenUnitsLayer2, classes], stddev=0.1))\n",
    "B3 = tf.Variable(tf.constant(0.1), [classes])\n",
    "\n",
    "hiddenLayerOutput = tf.matmul(X, W1) + B1\n",
    "hiddenLayerOutput = tf.nn.relu(hiddenLayerOutput)\n",
    "hiddenLayer2Output = tf.matmul(hiddenLayerOutput, W2) + B2\n",
    "hiddenLayer2Output = tf.nn.relu(hiddenLayer2Output)\n",
    "finalOutput = tf.matmul(hiddenLayer2Output, W3) + B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = finalOutput))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = .1).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(finalOutput,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.09\n",
      "step 1000, training accuracy 0.956\n",
      "step 2000, training accuracy 0.972\n",
      "step 3000, training accuracy 0.983\n",
      "step 4000, training accuracy 0.986\n",
      "step 5000, training accuracy 0.991\n",
      "step 6000, training accuracy 0.994\n",
      "step 7000, training accuracy 0.995\n",
      "step 8000, training accuracy 0.997\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(1000)\n",
    "    batchInput = batch[0]\n",
    "    batchLabels = batch[1]\n",
    "    _, trainingLoss = sess.run([opt, loss], feed_dict={X: batchInput, y: batchLabels})\n",
    "    if i%1000 == 0:\n",
    "        train_accuracy = accuracy.eval(session=sess, feed_dict={X: batchInput, y: batchLabels})\n",
    "        print (\"step %d, training accuracy %g\"%(i, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testInputs = mnist.test.images\n",
    "testLabels = mnist.test.labels\n",
    "acc = accuracy.eval(session=sess, feed_dict = {X: testInputs, y: testLabels})\n",
    "print(\"testing accuracy: {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
